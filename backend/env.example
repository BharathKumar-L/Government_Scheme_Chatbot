# Local LLM Configuration
# Choose one of the following options:

# Option 1: Ollama (requires Ollama installation)
USE_OLLAMA=true
OLLAMA_URL=http://localhost:11434
LOCAL_MODEL=llama2:7b
EMBEDDING_MODEL=nomic-embed-text

# Option 2: Hugging Face Transformers (requires @xenova/transformers)
USE_HUGGINGFACE=false
HF_LLM_MODEL=microsoft/DialoGPT-medium
HF_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Option 3: Simple Local LLM (default - no external dependencies)
# This is the default option that works out of the box

# Translation Services (Optional - Free alternatives are used by default)
# Google Translate API (optional - costs money)
GOOGLE_TRANSLATE_API_KEY=your_google_translate_api_key_here

# Free Translation Services (used by default)
# LibreTranslate: https://libretranslate.com/ (free)
# MyMemory: https://mymemory.translated.net/ (free with limits)
# No API keys needed for free services

# Redis Configuration (optional for caching)
REDIS_URL=redis://localhost:6379

# Server Configuration
PORT=3001
NODE_ENV=development

# ChromaDB Configuration
# You can specify either full URL in CHROMA_HOST or host + CHROMA_PORT
CHROMA_HOST=http://localhost
CHROMA_PORT=8000

# Data ingestion
# If true, training will read from LOCAL_DATA_PATH (fallback: backend/data/scraped_schemes.json)
USE_LOCAL_DATA=true
LOCAL_DATA_PATH="D:\FINAL YEAR PROJECT\Datasets\updated_data.csv"

# Ingestion batch size for vector DB adds
BATCH_SIZE=1000

# Rate Limiting
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100

# Admin Configuration
ADMIN_USERNAME=admin
ADMIN_PASSWORD=admin123!@#

MONGODB_URI=mongodb+srv://myAtlasDBUser:Bhk%252005%2F@myatlasclusteredu.u7d4pbu.mongodb.net/schemes